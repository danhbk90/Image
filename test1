// Atamakazu =o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=
//
// Atamakazu CPP : Copyright(C) 2014-2015 NEC Solution Innovators, Ltd. All Rights Reserved.
//
// =o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=o=

#include "atamakazu.h"

#define DEBUG false

// properties //////////////////////////////////////////

// フレーム番号
int atkFrameCount;
// 入退場者
double atkPeopleInCount;
double atkPeopleOutCount;

// 背景差分処理
BackgroundSubtractorMOG atkMog; // MOG
BackgroundSubtractorMOG2 atkMog2; // MOG2
BackgroundSubtractorGMG atkGmg; // GMG
double atkGgmMin = 0, atkGmgMax = 1;
Mat bgFrame; // AbsDiff用背景バッファ

IplImage iplTmp; // IplImage変換用

char imageName[100];

struct ATK_PROP prop;

CvVideoWriter* videoWriterSrc;
CvVideoWriter* videoWriterBgs;
CvVideoWriter* videoWriterFlw;
CvVideoWriter* videoWriterAll;
IplImage* iplBgs; // videoWriterBgs用
IplImage* iplAll; // videoWriterAll用

// Weighted Moving Variance
cv::Mat wmvPrev1;
cv::Mat wmvPrev2;
int wmvThreshold;
//20150310 add
//エリアより色をセット
const double areaColor[51][3]={{255,128,128},{128,64,64},{128,0,0},{64,0,0},{255,255,128},{255,255,0},{255,128,64},{255,128,0},{255,0,0},{0,0,255},{0,255,255},{255,128,255},{128,64,0},{128,128,0},{128,255,128},{128,255,0},{0,128,0},{0,64,0},{128,128,64},{0,255,128},{0,255,64},{0,128,128},{0,128,64},{0,64,64},{128,128,128},{128,255,255},{0,64,128},{0,0,128},{64,128,128},{0,128,255},{0,128,92},{128,128,255},{0,0,160},{0,0,64},{192,192,192},{255,128,192},{128,128,192},{128,0,64},{128,0,128},{64,0,64},{128,0,255},{255,255,255},{10,90,255},{0,0,0},{200,10,90},{255,30,80},{0,90,90},{90,100,100},{80,180,0},{120,60,10}};
//20150310 add end
// opticalflow
Mat optPrev, optNow;
IplImage areaImg;
// エリア階調：固定
int scaleStep = 5;
const int areaScales[51] = {5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255};
// エリア数（最大）：固定
const int areaNum = (sizeof areaScales)/(sizeof areaScales[0]);
// エリアサイズ（初期化処理でエリアの最大ピクセル数をカウントする。以降、エリアの有無もここで判断）
int areaSizes[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};

// 動体ピクセル数（現在のフレーム）
int movingPixels[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
// 累積動体ピクセル数（現在のフレーム）
int movingPixelsTotal[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
// 入退場別ベクトル（現在のフレーム）
double inVectors[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
double outVectors[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
// ユニット単位バッファ（ユニット単位で通過したら処理してクリア）
double countsBuf[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
double inVectorsBuf[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
double outVectorsBuf[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
bool unitPresentsBuf[51] = {false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false};

// 人数（出力用、処理開始からの累積）
double inCounts[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
double outCounts[51] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};

// ROI
cv::Rect roi;

// methods //////////////////////////////////////////

void atkGetAreaSize(){
	// エリア設定画像読み込み
	areaImg = IplImage(prop.areaImg);
	// 領域Index
	int areaIdx = 0;
	// ROI検出
	cv::Point roiMin(prop.areaImg.cols-1, prop.areaImg.rows-1);
	cv::Point roiMax(0, 0);

	// 画像全ピクセル処理
	for (int y = 0; y < areaImg.height; y++){
		for (int x = 0; x < areaImg.width; x++){
			// 背景画像の色取得
			uchar scale[3];
			scale[0] = areaImg.imageData[areaImg.widthStep * y + x * 3];     // B
			scale[1] = areaImg.imageData[areaImg.widthStep * y + x * 3 + 1]; // G
			scale[2] = areaImg.imageData[areaImg.widthStep * y + x * 3 + 2]; // R

			// グレースケール（RBGが等しい）、階調が0より大きく、かつ5で割りきれる場合に、
			// 領域と見做す　area scales 5, 10, ..., 55,60,75, ..., 255
			if(scale[0] == scale[1] && scale[1] == scale[2] && scale[0] > 0 && scale[0] % scaleStep == 0){
				areaIdx = (scale[0] - scaleStep) / scaleStep;
				// ただし、prop.movingUnit[]が存在するところだけをカウント対象エリアとする
				if(prop.movingUnit[areaIdx] != 0){
					// ピクセル数カウント
					areaSizes[areaIdx]++;

					// ROI調査
					if(x < roiMin.x) roiMin.x = x;
					if(x > roiMax.x) roiMax.x = x;
					if(y < roiMin.y) roiMin.y = y;
					if(y > roiMax.y) roiMax.y = y;
				}
			}
		}
	}

	// ROI決定
	if(roiMin.x == prop.areaImg.cols-1) roiMin.x = 0;
	if(roiMin.y == prop.areaImg.rows-1) roiMin.y = 0;
	if(roiMax.x == 0) roiMax.x = prop.areaImg.cols-1;
	if(roiMax.y == 0) roiMax.y = prop.areaImg.rows-1;
	roi.x = roiMin.x;
	roi.y = roiMin.y;
	roi.width = roiMax.x - roiMin.x;
	roi.height = roiMax.y - roiMin.y;

	// winsize分大きくとってみる
	if(roi.x > prop.winSize) roi.x = roi.x - prop.winSize;
	else roi.x = 0;
	if(roi.y > prop.winSize) roi.y = roi.y - prop.winSize;
	else roi.y = 0;
	if(roi.x + roi.width + prop.winSize * 2 < prop.areaImg.cols-1) roi.width = roi.width + prop.winSize * 2;
	else roi.width = prop.areaImg.cols-1;;
	if(roi.y + roi.height + prop.winSize * 2 < prop.areaImg.rows-1) roi.height = roi.height + prop.winSize * 2;
	else roi.height = prop.areaImg.rows-1;;

	// areaImgをROIで切り抜き
	prop.areaImg = Mat(prop.areaImg, roi);
	areaImg = IplImage(prop.areaImg);
	atkImageLog("area", &areaImg);
}

// initialize
bool atkInitialize(struct ATK_PROP propfrom,cv::Rect &roid){
	prop = propfrom;

	atkFrameCount = 0;
	atkPeopleInCount = 0;
	atkPeopleOutCount = 0;

	wmvThreshold = 30;

	// 各エリアのサイズをカウントして、areaSizes[]に格納、movingUnit[]と両方に値があるところだけを対象エリアとする。
	atkGetAreaSize();
	//20150310 add
	//set roi
	roid=roi;
	//20150310 add end
	return true;
}

cv::Mat weightedSquaredEuclidean(const cv::Mat &in1, const cv::Mat &in2, const double weight){
  cv::Mat diff(in1.size(), CV_32F);
  cv::absdiff(in1, in2, diff);
  cv::Mat pow(in1.size(), CV_32F);
  cv::pow(diff, 2.0, pow);
  return pow * weight;
}

void atkWMV(const cv::Mat &inframe, cv::Mat &outframe)
{
	if(inframe.empty()) return;

	// 1フレーム前
	if(wmvPrev1.empty()){
		inframe.copyTo(wmvPrev1);
		return;
	}

	// 2フレーム前
	if(wmvPrev2.empty()){
		wmvPrev1.copyTo(wmvPrev2);
		inframe.copyTo(wmvPrev1);
		return;
	}

	// weight
	double weight1 = 0.5;
	double weight2 = 0.3;
	double weight3 = 0.2;

	// Weighted mean　32Fに変換（全ピクセルを０～１にして計算）
	cv::Mat mean1(inframe.size(), CV_32F);
	cv::Mat mean2(inframe.size(), CV_32F);
	cv::Mat mean3(inframe.size(), CV_32F);
	cv::Mat mean(inframe.size(), CV_32F);
	inframe.convertTo(mean1, CV_32F, 1./255.);
	wmvPrev1.convertTo(mean2, CV_32F, 1./255.);
	wmvPrev2.convertTo(mean3, CV_32F, 1./255.);
	mean = ((mean1 * weight1) + (mean2 * weight2) + (mean3 * weight3));

	// Weighted variance
	cv::Mat var1(inframe.size(), CV_32F);
	cv::Mat var2(inframe.size(), CV_32F);
	cv::Mat var3(inframe.size(), CV_32F);
	cv::Mat var(inframe.size(), CV_32F);
	var1 = weightedSquaredEuclidean(mean1, mean, weight1);
	var2 = weightedSquaredEuclidean(mean2, mean, weight2);
	var3 = weightedSquaredEuclidean(mean3, mean, weight3);
	var = (var1 + var2 + var3);

	// 平方根
	cv::Mat sqrt(inframe.size(), CV_32F);
	cv::sqrt(var, sqrt);

	// 32F -> 8F　変換（０～１→０～２５５）
	cv::Mat conv(inframe.size(), CV_8U);
	sqrt.convertTo(conv, CV_8U, 255.0);

	conv.copyTo(outframe);

	// グレースケールに変換
	if(outframe.channels() == 3)
		cv::cvtColor(outframe, outframe, CV_BGR2GRAY);

	// 閾値で二値化
	if(wmvThreshold > 0)
		cv::threshold(outframe, outframe, wmvThreshold, 255, cv::THRESH_BINARY);

	wmvPrev1.copyTo(wmvPrev2);
	inframe.copyTo(wmvPrev1);
}

//	背景バッファ更新　atkBinalized　に出力
bool atkBackgroundSubtraction(Mat *frame) {
	bool ret = false;
	if (atkFrameCount == 0){
		switch (prop.bgsMethod){
			case BGS:
				atkWMV((*frame), atkBinalized);
				break;
			case MOG:
				atkMog((*frame), atkBinalized, 0.01f);
				break;
			case MOG2:
				atkMog2((*frame), atkBinalized);
				break;
			case GMG:
				atkGmg.numInitializationFrames = 40;
				atkGmg.initialize(frame->size(), atkGgmMin, atkGmgMax);
				break;
			case NONE:
				break;
			default:
				bgFrame = frame->clone();
				break;
		}
	}else{
		switch (prop.bgsMethod){
			case BGS:
				atkWMV((*frame), atkBinalized);
				if(atkFrameCount < 2) ret = false;
				else ret = true;
				break;
			case MOG:
				atkMog((*frame), atkBinalized, 0.01f);
				ret = true;
				break;
			case MOG2:
				atkMog2((*frame), atkBinalized);
				ret = true;
				break;
			case GMG:
				atkGmg((*frame), atkBinalized);
				ret = true;
				break;
			case NONE:
				ret = true;
				break;
			default:
				// 背景画像との差分を取得
				bgFrame = frame->clone();
				cvAbsDiff(frame->data, &bgFrame.data, &atkBinalized.data);

				// 差分画像をグレイスケールに
				iplTmp = IplImage(atkBinalized);
				IplImage* grayImage = cvCreateImage(cvGetSize(&iplTmp), IPL_DEPTH_8U, 1);
				cvCvtColor(&iplTmp, grayImage, CV_BGR2GRAY);

				// 画像ログ：グレイスケール画像
				atkImageLog("Cvt", grayImage);

				// 画像の二値化【判別分析法(大津の二値化)】
				cvThreshold (grayImage, grayImage, 0, 255, CV_THRESH_BINARY | CV_THRESH_OTSU);

				atkBinalized = grayImage;
				ret = true;
				break;
		}
	}

	atkFrameCount++;

	return ret;
}

void atkCount(Mat *frame,Mat &fFrame){
	// areaImgをROIで切り抜き
	Mat roiFrame = Mat((*frame), roi);
	// 初期化 //////////////////////////////////////
	if (atkFrameCount == 0){
		if(DEBUG){
			fprintf(stderr, "デバッグモードです\n");

			//表示ウィンドウの作成
			cvNamedWindow("Src");
			cvNamedWindow("Flow");
			cvNamedWindow("BgSub");
			cvNamedWindow("All");

			// VideoWriter
			videoWriterSrc = cvCreateVideoWriter("log/atkSrc.avi", CV_FOURCC('M','J','P','G'), 15, roiFrame.size(), 1);
			videoWriterBgs = cvCreateVideoWriter("log/atkBgSub.avi", CV_FOURCC('M','J','P','G'), 15, roiFrame.size(), 1);
			videoWriterFlw = cvCreateVideoWriter("log/atkFlow.avi", CV_FOURCC('M','J','P','G'), 15, roiFrame.size(), 1);
//			videoWriterAll = cvCreateVideoWriter("log/atkAll.avi", CV_FOURCC('M','J','P','G'), 15, cvSize(roiFrame.size().width, roiFrame.size().height * 3), 1);
			videoWriterAll = cvCreateVideoWriter("log/atkAll.avi", CV_FOURCC('M','J','P','G'), 15, cvSize(roiFrame.size().width, roiFrame.size().height * 2), 1);
			iplBgs = cvCreateImage(cvSize(roiFrame.size().width, roiFrame.size().height), IPL_DEPTH_8U, 3);
//			iplAll = cvCreateImage(cvSize(roiFrame.size().width, roiFrame.size().height * 3), IPL_DEPTH_8U, 3);
			iplAll = cvCreateImage(cvSize(roiFrame.size().width, roiFrame.size().height * 2), IPL_DEPTH_8U, 3);
		}
	}

	if(DEBUG){
		// 動画ログ：入力
		iplTmp = IplImage(roiFrame);
		atkVideoLog("Src", &iplTmp, videoWriterSrc);
		// 画像連結
		cvResetImageROI(iplAll);
		cvZero(iplAll);
		cvSetImageROI(iplAll, cvRect(0, 0, iplTmp.width, iplTmp.height));
		cvAdd(&iplTmp, iplAll, iplAll, NULL);
	}

	// 背景更新処理 //////////////////////////////
	if(!atkBackgroundSubtraction(&roiFrame)){
		// Previous image for Optical Flow
		cvtColor(roiFrame, optPrev, CV_BGR2GRAY);
		//20150310 change
		//return;
		//20150310 change end
	}


	if(prop.bgsMethod != NONE){
		//20150310 change
		// 画像ログ：背景差分画像（二値化）
		if(!(prop.bgsMethod == BGS && atkFrameCount < 3 )){
			iplTmp = IplImage(atkBinalized);
			atkImageLog("BgSub", &iplTmp);
		}
		//20150310 change end
	}
/*
	if(prop.debug){
		// 画像ログ：背景差分画像（二値化）
		iplTmp = IplImage(atkBinalized);
		atkVideoLog("BgSub", &iplTmp, videoWriterBgs);
		// 画像連結
		cvZero(iplBgs);
		atkCloneIgnoreDepth(&iplTmp, iplBgs);
		cvSetImageROI(iplAll, cvRect(0, iplTmp.height, iplTmp.width, iplTmp.height));
		cvAdd(iplBgs, iplAll, iplAll, NULL);
	}
*/
    // ベクトル取得処理
	//20150310 change
	//Mat flow;
	atkGetDirections(&roiFrame, &fFrame);
	//20150310 change end
	if(DEBUG){
		iplTmp = IplImage(fFrame);
		// 画像ログ：フロー画像
		atkVideoLog("Flow", &iplTmp, videoWriterFlw);
		// 画像連結
		//cvSetImageROI(iplAll, cvRect(0, iplTmp.height*2, iplTmp.width, iplTmp.height));
		cvSetImageROI(iplAll, cvRect(0, iplTmp.height, iplTmp.width, iplTmp.height));
		cvAdd(&iplTmp, iplAll, iplAll, NULL);
		cvResetImageROI(iplAll);
		atkVideoLog("All", iplAll, videoWriterAll);
	}

	// エリア別動体カウント for 背景差分
	if(prop.bgsMethod != NONE){
		atkGetMovingCount(&atkBinalized);
	}

	// 人数分配処理
	atkAreaCount();

	//表示ウィンドウの描画待ち
	cvWaitKey(15);
}

// ベクトル取得　frame:取得画像、area:エリア設定画像
void atkGetDirections(Mat *frame, Mat *dst){
	// 入力：フレーム番号、frame:取得画像、area:エリア設定画像

	// オプティカルフロー実施
	// 検出した全ベクトルを入場方向ベクトルと退場方向ベクトルに分けて、エリア別に加算
	cvtColor((*frame), optNow, CV_BGR2GRAY);
	Mat flow;
	calcOpticalFlowFarneback(optPrev, optNow, flow, 0.5, 3, prop.winSize, 3, 5, 1.2, 0);
	// trace log
	//20150310 change
	//if(DEBUG){
	cvtColor(optNow, (*dst), CV_GRAY2BGR);
	//}
	//20150310 change end
	// 現フレーム動体ピクセル数、入退場ベクトル、初期化　★★★★★★★★★
	for(int i=0; i<areaNum ;i++){
		movingPixels[i] = 0;
		inVectors[i] = 0;
		outVectors[i] = 0;
	}
	// 画像全ピクセル処理
	for (int y = 0; y < flow.rows; y += prop.step){
		for (int x = 0; x < flow.cols; x += prop.step) {

			// ベクトル（x差分とy差分）
			const Point2f& fxy = flow.at<Point2f>(y, x);

			// ベクトルの長さ（三平方の定理より、２点間の距離を求める）
			double edistance = hypot(fxy.x, fxy.y);

			// 現ピクセル＋ベクトル（≠移動元）
			Point movePoint = Point(cvRound(x + fxy.x), cvRound(y + fxy.y));
			//20150310 add
			// 領域Index
			int areaIdx = 0;
			// Roiを分割
			uchar s[3];
			s[0] = areaImg.imageData[areaImg.widthStep * y + x * 3];     // B
			s[1] = areaImg.imageData[areaImg.widthStep * y + x * 3 + 1]; // G
			s[2] = areaImg.imageData[areaImg.widthStep * y + x * 3 + 2]; // R
			if(s[0] == s[1] && s[1] == s[2] && s[0] > 0 && s[0] % scaleStep == 0){
				areaIdx = (s[0] - scaleStep) / scaleStep;
				if(s[0]==s[1] && s[1]==s[2] && s[0]>0 && s[0]%scaleStep==0 && areaSizes[areaIdx]>0){
					circle((*dst), Point(x, y), 2, CV_RGB(areaColor[areaIdx-1][0], areaColor[areaIdx-1][1], areaColor[areaIdx-1][2]), -1);
				}
			}
			//20150310 add end
			// 移動距離が設定以内であること
			if (edistance >= prop.minDistance && edistance <= prop.maxDistance) {

				// 画面外からベクトルは無視
				if (y - fxy.y >= 0 && y - fxy.y < flow.rows
						&& x - fxy.x >= 0 && x - fxy.x < flow.cols) {

					line((*dst), Point(x, y), movePoint, CV_RGB(0, 255, 0));
					circle((*dst), Point(x, y), 1, CV_RGB(0, 255, 0), -1);

					if(areaIdx >= 0){
						if(s[0]==s[1] && s[1]==s[2] && s[0]>0 && s[0]%scaleStep==0 && areaSizes[areaIdx]>0){

							if(fxy.y > 0){
								// inVectors[]：入場方向ベクトル（エリア別、現フレーム累計y軸長（>=0））
								inVectors[areaIdx] += abs(fxy.y);
								// trace log
								if(DEBUG){
									cerr << "inVctors[" << areaIdx << "]=" << inVectors[areaIdx] << endl;
								}
							}else if(fxy.y < 0){
								// outVectors[]：退場方向ベクトル（エリア別、現フレーム累計y軸長（>=0））
								outVectors[areaIdx] += abs(fxy.y);
								// trace log
								if(DEBUG){
								cerr << "outVctors[" << areaIdx << "]=" << outVectors[areaIdx] << endl;
								}
							}
							if(prop.bgsMethod == NONE){
								// カウント累積　for OPT
								movingPixels[areaIdx]++;
								movingPixelsTotal[areaIdx]++;
							}
						}
					}
				}
			}
		}
	}
	optPrev = optNow.clone();

	// 出力：double
	// inVectors[]：入場方向ベクトル（エリア別、現フレーム累計y軸長（>=0））
	// outVectors[]：退場方向ベクトル（エリア別、現フレーム累計y軸長（>=0））
};

// 出力用人数算出　counts:エリア別人数
double atkSetCount(double *counts){
	double count = 0;
	int cntArea = 0;

	// 全エリア累積
	for(int i = 0; i < areaNum; i++){
		if(areaSizes[i] > 0){
			count += counts[i];
			cntArea++;
		}
	}

	// エリア平均
	if(cntArea > 0) count = count / cntArea;
	else return count = 0;

	return count;
}

// 現フレームの背景差分からエリア別動体ピクセル数取得
void atkGetMovingCount(Mat *frame){

	// 初期化
	for(int i=0; i<areaNum ;i++) movingPixels[i] = 0;

	int step = 1;
	// 画像全ピクセル処理
	for (int y = 0; y < frame->rows; y += step){
		for (int x = 0; x < frame->cols; x += step) {

			// 動体検出用二値化画像
			uchar p[3];
			p[0] = frame->data[frame->step * y + x * 3];     // B
			p[1] = frame->data[frame->step * y + x * 3 + 1]; // G
			p[2] = frame->data[frame->step * y + x * 3 + 2]; // R

			// 領域設定画像
			uchar s[3];
			s[0] = areaImg.imageData[areaImg.widthStep * y + x * 3];     // B
			s[1] = areaImg.imageData[areaImg.widthStep * y + x * 3 + 1]; // G
			s[2] = areaImg.imageData[areaImg.widthStep * y + x * 3 + 2]; // R

			// グレースケール（RBGが等しい）、階調が0より大きく、かつ5で割りきれる、かつエリアサイズが設定されている場合に、
			// 領域と見做す　area scales 5,10,...,55,60,75,...,255
			int areaIdx = (s[0] - scaleStep) / scaleStep;
			if(s[0]==s[1] && s[1]==s[2] && s[0]>0 && s[0]%scaleStep==0 && areaSizes[areaIdx]>0){
				// 0の場合は色を累積する
				if (p[0] == 255 && p[1] == 255 && p[2] == 255) {
					movingPixels[areaIdx]++;
					movingPixelsTotal[areaIdx]++;
				}
			}
		}
	}
}

// エリア別カウント
void atkAreaCount(){
	// 入力：
	// inVectors[]：入場方向ベクトル（エリア別、現フレーム累計y軸長（>=0））
	// outVectors[]：退場方向ベクトル（エリア別、現フレーム累計y軸長（>=0））

	// エリアでループ
	for(int i = 0; i < areaNum; i++){
		// エリアがなければ次のエリア
		if(areaSizes[i] == 0) continue;

		// エリア別でノイズピクセル数以上のカウントが検出されたら
		if(movingPixels[i] > prop.noise){
			// ユニット通過中
			unitPresentsBuf[i] = true; // ユニット通過中フラグ

			// エリア別動体ピクセル数を人数換算
			double count = (double)movingPixels[i]/(double)prop.movingUnit[i];

			// 現ユニットの入退場人数カウントバッファに加算
			countsBuf[i] += count;

			// 現ユニットの入退場ベクトルバッファに加算
			inVectorsBuf[i] += inVectors[i];
			outVectorsBuf[i] += outVectors[i];
		}else{
			// 動体検出なし

			// ユニット通過直後
			if(unitPresentsBuf[i]){

				// 累積入退場人数に現ユニットの人数を加算
				if((inVectorsBuf[i] + outVectorsBuf[i])>0){
					double inCount = countsBuf[i] * inVectorsBuf[i]/(inVectorsBuf[i] + outVectorsBuf[i]);
					inCounts[i] += inCount;
					outCounts[i] += countsBuf[i] - inCount;
					//outCounts[i] += countsBuf[i] * outVectorsBuf[i]/(inVectorsBuf[i] + outVectorsBuf[i]);
				}

				// 出力用累積入退場人数を更新
				atkPeopleInCount = atkSetCount(inCounts);
				atkPeopleOutCount = atkSetCount(outCounts);

				// trace log
				if(DEBUG){
					cerr << "エリア " << i << " をユニットが通過！！！！！！" << atkPeopleInCount << "," << atkPeopleOutCount << endl;
				}

				// 現ユニットのバッファクリア
				countsBuf[i] = 0; // 現ユニットのピクセル数
				inVectorsBuf[i] = 0; // 現ユニットの入場方向ベクトル（エリア別、現ユニット累計y軸長（>=0））
				outVectorsBuf[i] = 0; // 現ユニットの退場方向ベクトル（エリア別、現ユニット累計y軸長（>=0））
				unitPresentsBuf[i] = false; // ユニット通過中フラグ
			}
		}
	}
};


double atkGetTimeOfDay(double starttime){
	struct timeval now;
	gettimeofday(&now, NULL);
	double nowtime = (now.tv_sec + now.tv_usec/1000000.0);
	return nowtime - starttime;
}

void atkCloneIgnoreDepth(IplImage *src, IplImage* dst){
	for(int y = 0; y < src->height; y++){
		for(int x = 0; x < src->width; x++){
			if(src->nChannels == 1 && dst->nChannels == 3){
				cvSet2D(dst, y, x, cvScalar(cvGet2D(src, y, x).val[0], cvGet2D(src, y, x).val[0], cvGet2D(src, y, x).val[0], 0));
			}else{
				cvSet2D(dst, y, x, cvGet2D(src, y, x));
			}
		}
	}
}

// 入場者数取得
double atkGetInCount(){
	return atkPeopleInCount;
}

// 退場者数取得
double atkGetOutCount(){
	return atkPeopleOutCount;
}

// フレーム番号取得
int atkGetFrameCount(){
	return atkFrameCount;
}

void atkRelease(){
	cvReleaseVideoWriter(&videoWriterSrc);
	cvReleaseVideoWriter(&videoWriterBgs);
	cvReleaseVideoWriter(&videoWriterFlw);
	cvReleaseVideoWriter(&videoWriterAll);
	if(iplAll){
		cvReleaseImage(&iplAll);
		iplAll = NULL;
	}
	if(iplBgs){
		cvReleaseImage(&iplBgs);
		iplBgs = NULL;
	}
}

void atkImageLog(const char* propName, IplImage* ipl){
	if(DEBUG){
		sprintf(imageName, "log/img/%d_%s.jpg", atkFrameCount, propName);
		cvSaveImage(imageName, ipl);
	}
}

void atkVideoLog(const char* winName, IplImage* ipl, CvVideoWriter* videoSrc){
	if(DEBUG){
		atkImageLog(winName, ipl);
		cvShowImage (winName, ipl); //表示ウィンドウに描画
		cvWriteFrame(videoSrc, ipl);
	}
}

int* atkGetMovingPixels(){
	return movingPixelsTotal;
}

int* atkGetAreaSizes(){
	return areaSizes;
}
//20150310 add
double* atkGetinVectors()
{
	return inVectors;
}
double* atkGetoutVectors()
{
	return outVectors;
}
//20150310 add end
